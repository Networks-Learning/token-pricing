{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b894938",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from src import utils\n",
    "from src.opt_tok import optimal_tokenization\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(1):\n",
    "    with open(f'/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/shortest_vs_factual_modelMinistral-8B-Instruct-2410_p1.0_kNone_numseq10_numprompts30_maxoutlen200_temp2.0_id{1+i}.pkl', 'rb') as file:\n",
    "        data=data+pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tokenizer if need\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Ministral-8B-Instruct-2410\")\n",
    "print(tokenizer.decode(data[10][\"output\"][9][-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[20][\"prompt\"])\n",
    "print(len([i.item() for i in data[20][\"output\"][0]]))\n",
    "#print(tokenizer.decode(data[11][\"output\"][0]))\n",
    "print(data[20][\"optimal_lengths\"][0])\n",
    "#print(optimal_tokenization(tokenizer.decode(data[11][\"output\"][0]), tokenizer)[\"ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratios = []\n",
    "for i in range(len(data)):\n",
    "    for seq in range(len(data[i][\"output\"])):\n",
    "\n",
    "        if len(data[i][\"output\"][seq])>0:\n",
    "\n",
    "\n",
    "            ratios.append(data[i][\"optimal_lengths\"][seq] / len(data[i][\"output\"][seq]))            \n",
    "\n",
    "\n",
    "#Remove outliers, normally due to non-standar characters\n",
    "ratios = [(1-ratio)*100 for ratio in ratios if 1>=ratio>=0.95]\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/ratios_8B.pkl', 'wb') as file:\n",
    "    pickle.dump(ratios, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/ratios_1B.pkl', 'rb') as file:\n",
    "    ratios_L1B = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/ratios_3B.pkl', 'rb') as file:\n",
    "    ratios_L3B = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/ratios_1B.pkl', 'rb') as file:\n",
    "    ratios_G1B = pickle.load(file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/ratios_4B.pkl', 'rb') as file:\n",
    "    ratios_G4B = pickle.load(file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/ratios_8B.pkl', 'rb') as file:\n",
    "    ratios_M8B = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': ratios_L1B + ratios_L3B ,\n",
    "    'model': ['1B'] * len(ratios_L1B) + ['3B'] * len(ratios_L3B) \n",
    "})\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=palette, ax=ax, bins=15, legend=False, kde=False, multiple=\"dodge\", shrink=0.8)  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[0], edgecolor=\"white\", label=\"Llama-3.2-1B-Instruct\"),  # Color and label for 1B\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Llama-3.2-3B-Instruct\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "ax.axvline(np.mean(ratios_L1B), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(ratios_L3B), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in number of output tokens ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "#ax.set_xticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_L.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': ratios_G1B + ratios_G4B ,\n",
    "    'model': ['1B'] * len(ratios_G1B) + ['4B'] * len(ratios_G4B) \n",
    "})\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=palette, ax=ax, bins=15, legend=False, kde=False, stat=\"probability\", multiple=\"dodge\", shrink=0.8 )  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[0], edgecolor=\"white\", label=\"Gemma-3-1B-It\"),  # Color and label for 1B\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Gemma-3-4B-It\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "ax.axvline(np.mean(ratios_G1B), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(ratios_G4B), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in number of output tokens ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "#ax.set_xticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_G.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': ratios_M8B ,\n",
    "    'model': ['8B'] * len(ratios_M8B) \n",
    "})\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1],palette[0]], ax=ax, bins=15, legend=False, kde=False, stat=\"probability\", multiple=\"dodge\", shrink=0.8)  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Ministral-8B-Instruct\"),  # Color and label for 1B\n",
    "    #Patch(facecolor=palette[2], edgecolor=\"white\", label=\"Gemma-3-4B-It\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in number of output tokens ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "#ax.set_xticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "ax.axvline(np.mean(ratios_M8B), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_M.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5196db",
   "metadata": {},
   "source": [
    "# Plots with cost/price using percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(18):\n",
    "    with open(f'/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/shortest_vs_factual_modelLlama-3.2-3B-Instruct_p1.0_kNone_numseq10_numprompts30_maxoutlen200_temp2.0_id{1+i}.pkl', 'rb') as file:\n",
    "        data=data+pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tok_fact_G1B = 0\n",
    "num_tok_opt_G1B = 0\n",
    "num_char_G1B = 0\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\") \n",
    "for i in range(len(data)):\n",
    "    for seq in range(len(data[i][\"output\"])):\n",
    "\n",
    "        if ( len(data[i][\"output\"][seq])>0 )and (0.5< data[i][\"optimal_lengths\"][seq] / len(data[i][\"output\"][seq]) < 1):\n",
    "            num_tok_fact_G1B += len(data[i][\"output\"][seq])\n",
    "            num_tok_opt_G1B += data[i][\"optimal_lengths\"][seq]\n",
    "            num_char_G1B += len(tokenizer.decode(data[i][\"output\"][seq]))\n",
    "            \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/num_char_G1B.pkl', 'wb') as file:\n",
    "     pickle.dump(num_char_G1B,file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/num_tok_fact_G1B.pkl', 'wb') as file:\n",
    "    pickle.dump(num_tok_fact_G1B,file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/num_tok_opt_G1B.pkl', 'wb') as file:\n",
    "    pickle.dump(num_tok_opt_G1B,file)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/num_char_M8B.pkl', 'rb') as file:\n",
    "     num_char_M8B = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/tok_opt_M8B.pkl', 'rb') as file:\n",
    "     num_tok_opt_M8B = pickle.load(file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/tok_fac_M8B.pkl', 'rb') as file:\n",
    "     num_tok_fact_M8B = pickle.load(file)\n",
    "     \n",
    "     \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/num_char_G4B.pkl', 'rb') as file:\n",
    "        num_char_G4B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/tok_opt_G4B.pkl', 'rb') as file:\n",
    "        num_tok_opt_G4B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/tok_fac_G4B.pkl', 'rb') as file:    \n",
    "        num_tok_fact_G4B = pickle.load(file)\n",
    "        \n",
    "        \n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/num_char_G1B.pkl', 'rb') as file:\n",
    "        num_char_G1B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/tok_opt_G1B.pkl', 'rb') as file:\n",
    "        num_tok_opt_G1B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/tok_fac_G1B.pkl', 'rb') as file:\n",
    "        num_tok_fact_G1B = pickle.load(file)\n",
    "        \n",
    "        \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/num_char_L1B.pkl', 'rb') as file:\n",
    "        num_char_L1B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/tok_opt_L1B.pkl', 'rb') as file:\n",
    "        num_tok_opt_L1B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/tok_fac_L1B.pkl', 'rb') as file:\n",
    "        num_tok_fact_L1B = pickle.load(file)\n",
    "        \n",
    "        \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/num_char_L3B.pkl', 'rb') as file:\n",
    "        num_char_L3B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tok_opt_L3B.pkl', 'rb') as file:\n",
    "        num_tok_opt_L3B = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tok_fac_L3B.pkl', 'rb') as file:\n",
    "        num_tok_fact_L3B = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 5)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "x = np.linspace(0, 4, 100)\n",
    "increase_M8B = ( (num_char_M8B - x * num_tok_opt_M8B) / (num_char_M8B - x * num_tok_fact_M8B) - 1)*100\n",
    "increase_L3B = ( (num_char_L3B - x * num_tok_opt_L3B) / (num_char_L3B - x * num_tok_fact_L3B) - 1)*100\n",
    "increase_L1B = ( (num_char_L1B - x * num_tok_opt_L1B) / (num_char_L1B - x * num_tok_fact_L1B) - 1)*100\n",
    "increase_G1B = ( (num_char_G1B - x * num_tok_opt_G1B) / (num_char_G1B - x * num_tok_fact_G1B) - 1)*100\n",
    "increase_G4B = ( (num_char_G4B - x * num_tok_opt_G4B) / (num_char_G4B - x * num_tok_fact_G4B) - 1)*100\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y': np.concatenate((increase_M8B,increase_L1B,increase_L3B,increase_G1B,increase_G4B)),\n",
    "    'x': np.concatenate((x,x,x,x,x)),\n",
    "    'model' : ['M8B']*len(increase_M8B) + ['L1B']*len(increase_L1B) + ['L3B']*len(increase_L3B) + ['G1B']*len(increase_G1B) + ['G4B']*len(increase_G4B)\n",
    "})\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.lineplot(data = df, x=\"x\",y=\"y\",color=palette, hue=\"model\" ,ax=ax, legend=True, linestyle=\"--\", errorbar=None)  \n",
    "\n",
    "ax.get_legend().set_title(None)\n",
    "ax.legend(labels=[\"Ministral-8B-Instruct\", \"Llama-3.2-1B-Instruc\", \"Llama-3.2-3B-Instruc\",\"Gemma-3-1B-It\",\"Gemma-3-4B-It\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Cost of token generation ($\\lambda$)/ price of character ($\\alpha$)\")\n",
    "ax.set_ylabel(\"Change in profit\", fontsize=\"small\")\n",
    "#ax.set_yticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(num_char_M8B / num_tok_fact_M8B)\n",
    "print((num_char_G1B / num_tok_opt_G1B)/2 + (num_char_G4B / num_tok_opt_G4B)/2)\n",
    "print((num_char_L1B / num_tok_opt_L1B)/2 + (num_char_L3B / num_tok_opt_L3B)/2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96436311",
   "metadata": {},
   "source": [
    "# Plots distribution of profit for different c/p using percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(18):\n",
    "    with open(f'/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/shortest_vs_factual_modelLlama-3.2-3B-Instruct_p1.0_kNone_numseq10_numprompts30_maxoutlen200_temp2.0_id{i+1}.pkl', 'rb') as file:\n",
    "        data=data+pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters, tokens, optimal_tokens = [], [], []\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "for i in range(len(data)):\n",
    "    for seq in range(len(data[i][\"output\"])):\n",
    "\n",
    "        if len(data[i][\"output\"][seq])>0:\n",
    "            characters.append(len(tokenizer.decode(data[i][\"output\"][seq])))\n",
    "            tokens.append(len(data[i][\"output\"][seq]))\n",
    "            optimal_tokens.append(data[i][\"optimal_lengths\"][seq])\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/characters_L3B.pkl', 'wb') as file:\n",
    "     pickle.dump(characters,file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tokens_L3B.pkl', 'wb') as file:\n",
    "     pickle.dump(tokens,file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/optimal_tokens_L3B.pkl', 'wb') as file: \n",
    "     pickle.dump(optimal_tokens,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/characters_L3B.pkl', 'rb') as file:\n",
    "     characters = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tokens_L3B.pkl', 'rb') as file:\n",
    "     tokens = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/optimal_tokens_L3B.pkl', 'rb') as file:\n",
    "     optimal_tokens = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 3)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "y_cp1 = [ ((characters[i] - 1 * optimal_tokens[i]) / (characters[i] - 1 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp09 = [ ((characters[i] - 0.9 * optimal_tokens[i]) / (characters[i] - 0.9 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp08 = [ ((characters[i] - 0.8 * optimal_tokens[i]) / (characters[i] - 0.8 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp1 = [i for i in y_cp1 if i<1.25]\n",
    "y_cp09 = [i for i in y_cp09 if i<1.25]\n",
    "y_cp08 = [i for i in y_cp08 if i<1.25]\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'profits':  y_cp1 + y_cp09 + y_cp08,\n",
    "    'cp' : ['cp1']*len(y_cp1) + ['cp09']*len(y_cp09) + ['cp08']*len(y_cp08)\n",
    "})\n",
    "\n",
    "hist = sns.histplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, multiple = \"dodge\", kde=False, bins=np.linspace(0,1.2,15), shrink=0.8, alpha=0.7)  # Histogram with KDE\n",
    "\n",
    "#sns.kdeplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, clip=(0,1.25))\n",
    "# Add a vertical line for the mean\n",
    "ax.axvline(np.mean(y_cp1), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp09), color=palette[1], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp08), color=palette[2], linestyle=\"--\")\n",
    "\n",
    "\n",
    "ax.legend(labels=[r\"$\\frac{\\lambda}{\\alpha}=1$\", r\"$\\frac{\\lambda}{\\alpha}=0.9$\", r\"$\\frac{\\lambda}{\\alpha}=0.8$\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "#ax.set_xlabel(r\"Cost of token genreation / price of character \")\n",
    "ax.set_xlabel(r\"Change in provider profit ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=\"small\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs_dist_L3B.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/characters_L1B.pkl', 'rb') as file:\n",
    "     characters = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/tokens_L1B.pkl', 'rb') as file:\n",
    "     tokens = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/optimal_tokens_L1B.pkl', 'rb') as file:\n",
    "     optimal_tokens = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 3)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "y_cp1 = [ ((characters[i] - 1 * optimal_tokens[i]) / (characters[i] - 1 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp09 = [ ((characters[i] - 0.9 * optimal_tokens[i]) / (characters[i] - 0.9 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp08 = [ ((characters[i] - 0.8 * optimal_tokens[i]) / (characters[i] - 0.8 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp1 = [i for i in y_cp1 if i<1.25]\n",
    "y_cp09 = [i for i in y_cp09 if i<1.25]\n",
    "y_cp08 = [i for i in y_cp08 if i<1.25]\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'profits':  y_cp1 + y_cp09 + y_cp08,\n",
    "    'cp' : ['cp1']*len(y_cp1) + ['cp09']*len(y_cp09) + ['cp08']*len(y_cp08)\n",
    "})\n",
    "\n",
    "hist = sns.histplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, multiple =\"dodge\", kde=False, bins=np.linspace(0,1.2,15), shrink=0.8, alpha=0.7)  # Histogram with KDE\n",
    "\n",
    "#sns.kdeplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, clip=(0,1.25))\n",
    "\n",
    "ax.axvline(np.mean(y_cp1), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp09), color=palette[1], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp08), color=palette[2], linestyle=\"--\")\n",
    "ax.legend(labels=[r\"$\\frac{\\lambda}{\\alpha}=1$\", r\"$\\frac{\\lambda}{\\alpha}=0.9$\", r\"$\\frac{\\lambda}{\\alpha}=0.8$\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "#ax.set_xlabel(r\"Cost of token genreation / price of character \")\n",
    "ax.set_xlabel(r\"Change in provider profit ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=\"small\")\n",
    "#ax.set_yticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs_dist_L1B.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50013d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/characters_G1B.pkl', 'rb') as file:\n",
    "     characters = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/tokens_G1B.pkl', 'rb') as file:\n",
    "     tokens = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/optimal_tokens_G1B.pkl', 'rb') as file:\n",
    "     optimal_tokens = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 3)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "y_cp1 = [ ((characters[i] - 1 * optimal_tokens[i]) / (characters[i] - 1 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp09 = [ ((characters[i] - 0.9 * optimal_tokens[i]) / (characters[i] - 0.9 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp08 = [ ((characters[i] - 0.8 * optimal_tokens[i]) / (characters[i] - 0.8 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp1 = [i for i in y_cp1 if i<1.25]\n",
    "y_cp09 = [i for i in y_cp09 if i<1.25]\n",
    "y_cp08 = [i for i in y_cp08 if i<1.25]\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'profits':  y_cp1 + y_cp09 + y_cp08,\n",
    "    'cp' : ['cp1']*len(y_cp1) + ['cp09']*len(y_cp09) + ['cp08']*len(y_cp08)\n",
    "})\n",
    "\n",
    "hist = sns.histplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, multiple =\"dodge\", kde=False, bins=np.linspace(0,1.2,15), shrink=0.8, alpha=0.7)  # Histogram with KDE\n",
    "\n",
    "#sns.kdeplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, clip=(0,1.25))\n",
    "\n",
    "ax.axvline(np.mean(y_cp1), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp09), color=palette[1], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp08), color=palette[2], linestyle=\"--\")\n",
    "ax.legend(labels=[r\"$\\frac{\\lambda}{\\alpha}=1$\", r\"$\\frac{\\lambda}{\\alpha}=0.9$\", r\"$\\frac{\\lambda}{\\alpha}=0.8$\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "#ax.set_xlabel(r\"Cost of token genreation / price of character \")\n",
    "ax.set_xlabel(r\"Change in provider profit ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=\"small\")\n",
    "#ax.set_yticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs_dist_G1B.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de216c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/characters_G4B.pkl', 'rb') as file:\n",
    "     characters = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/tokens_G4B.pkl', 'rb') as file:\n",
    "     tokens = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/optimal_tokens_G4B.pkl', 'rb') as file:\n",
    "     optimal_tokens = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 3)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "y_cp1 = [ ((characters[i] - 1 * optimal_tokens[i]) / (characters[i] - 1 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp09 = [ ((characters[i] - 0.9 * optimal_tokens[i]) / (characters[i] - 0.9 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp08 = [ ((characters[i] - 0.8 * optimal_tokens[i]) / (characters[i] - 0.8 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp1 = [i for i in y_cp1 if i<1.25]\n",
    "y_cp09 = [i for i in y_cp09 if i<1.25]\n",
    "y_cp08 = [i for i in y_cp08 if i<1.25]\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'profits':  y_cp1 + y_cp09 + y_cp08,\n",
    "    'cp' : ['cp1']*len(y_cp1) + ['cp09']*len(y_cp09) + ['cp08']*len(y_cp08)\n",
    "})\n",
    "\n",
    "hist = sns.histplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, multiple =\"dodge\", kde=False, bins=np.linspace(0,1.2,15), shrink=0.8, alpha=0.7)  # Histogram with KDE\n",
    "\n",
    "#sns.kdeplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, clip=(0,1.25))\n",
    "ax.axvline(np.mean(y_cp1), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp09), color=palette[1], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp08), color=palette[2], linestyle=\"--\")\n",
    "\n",
    "ax.legend(labels=[r\"$\\frac{\\lambda}{\\alpha}=1$\", r\"$\\frac{\\lambda}{\\alpha}=0.9$\", r\"$\\frac{\\lambda}{\\alpha}=0.8$\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "#ax.set_xlabel(r\"Cost of token genreation / price of character \")\n",
    "ax.set_xlabel(r\"Change in provider profit ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=\"small\")\n",
    "#ax.set_yticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs_dist_G4B.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e558a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/characters_M8B.pkl', 'rb') as file:\n",
    "     characters = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/tokens_M8B.pkl', 'rb') as file:\n",
    "     tokens = pickle.load(file)\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/optimal_tokens_M8B.pkl', 'rb') as file:\n",
    "     optimal_tokens = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 3)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "y_cp1 = [ ((characters[i] - 1 * optimal_tokens[i]) / (characters[i] - 1 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp09 = [ ((characters[i] - 0.9 * optimal_tokens[i]) / (characters[i] - 0.9 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp08 = [ ((characters[i] - 0.8 * optimal_tokens[i]) / (characters[i] - 0.8 * tokens[i] ) -1 )*100 for i in range(len(characters)) if (optimal_tokens[i]/tokens[i] > 0.95) and (optimal_tokens[i]/tokens[i] < 1) and (characters[i]>optimal_tokens[i])]\n",
    "\n",
    "y_cp1 = [i for i in y_cp1 if i<1.25]\n",
    "y_cp09 = [i for i in y_cp09 if i<1.25]\n",
    "y_cp08 = [i for i in y_cp08 if i<1.25]\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'profits':  y_cp1 + y_cp09 + y_cp08,\n",
    "    'cp' : ['cp1']*len(y_cp1) + ['cp09']*len(y_cp09) + ['cp08']*len(y_cp08)\n",
    "})\n",
    "\n",
    "hist = sns.histplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, multiple =\"dodge\", kde=False, bins=np.linspace(0,1.2,15), shrink=0.8, alpha=0.7)  # Histogram with KDE\n",
    "\n",
    "#sns.kdeplot(data = df, x=\"profits\", hue=\"cp\", palette=palette ,ax=ax, legend=True, clip=(0,1.25))\n",
    "\n",
    "ax.axvline(np.mean(y_cp1), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp09), color=palette[1], linestyle=\"--\")\n",
    "ax.axvline(np.mean(y_cp08), color=palette[2], linestyle=\"--\")\n",
    "ax.legend(labels=[r\"$\\frac{\\lambda}{\\alpha}=1$\", r\"$\\frac{\\lambda}{\\alpha}=0.9$\", r\"$\\frac{\\lambda}{\\alpha}=0.8$\"], fontsize=8)  # Update the labels\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "#ax.set_xlabel(r\"Cost of token genreation / price of character \")\n",
    "ax.set_xlabel(r\"Change in provider profit ($\\%$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=\"small\")\n",
    "#ax.set_yticks([ 0,1,2,3,4,5], [r\"0\\%\",r\"1\\%\",r\"2\\%\",r\"3\\%\",r\"4\\%\",r\"5\\%\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/profit_dp_mult_costs_dist_m8B.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9fa5cb",
   "metadata": {},
   "source": [
    "# Plots dp using absulute differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb051e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/optimal_tokens_L1B.pkl', 'rb') as file:\n",
    "    L1B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/tokens_L1B.pkl', 'rb') as file:\n",
    "    L1B_fact = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/optimal_tokens_L3B.pkl', 'rb') as file:\n",
    "    L3B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tokens_L3B.pkl', 'rb') as file:\n",
    "    L3B_fact = pickle.load(file)\n",
    "\n",
    "\n",
    "L1B_dif = [L1B_fact[i]-L1B_opt[i] for i in range(len(L1B_fact)) if 10>L1B_fact[i]-L1B_opt[i]>=0]\n",
    "L3B_dif = [L3B_fact[i]-L3B_opt[i] for i in range(len(L3B_fact)) if 10>L3B_fact[i]-L3B_opt[i]>=0]\n",
    "\n",
    "L1B_dif = L1B_dif[0:min(len(L1B_dif),len(L3B_dif))]\n",
    "L3B_dif = L3B_dif[0:min(len(L1B_dif),len(L3B_dif))]\n",
    "\n",
    "L1B_dif = L1B_dif[0:3600]\n",
    "L3B_dif = L3B_dif[0:3600]\n",
    "\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': L1B_dif + L3B_dif ,\n",
    "    'model': ['1B'] * len(L1B_dif) + ['3B'] * len(L3B_dif) \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=palette, ax=ax, bins=np.arange(-0.5, 9, 1.0), legend=False, kde=False, multiple=\"dodge\")  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[0], edgecolor=\"white\", label=\"Llama-3.2-1B-Instruct\"),  # Color and label for 1B\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Llama-3.2-3B-Instruct\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "ax.axvline(np.mean(L1B_dif), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(L3B_dif), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in provider profit  (units of $c_0$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "ax.set_xticks([ 0,1,2,3,4,5,6,7,8], [r\"0\",r\"1\",r\"2\",r\"3\",r\"4\",r\"5\",\"6\",r\"7\",r\"8\"])\n",
    "ax.set_xlim([-0.5,6])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_L_absolute.pdf', dpi=300)\n",
    "print(len(L1B_dif))\n",
    "print(len(L3B_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/optimal_tokens_G1B.pkl', 'rb') as file:\n",
    "    G1B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/tokens_G1B.pkl', 'rb') as file:\n",
    "    G1B_fact = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/optimal_tokens_G4B.pkl', 'rb') as file:\n",
    "    G4B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/tokens_G4B.pkl', 'rb') as file:\n",
    "    G4B_fact = pickle.load(file)\n",
    "\n",
    "\n",
    "G1B_dif = [G1B_fact[i]-G1B_opt[i] for i in range(len(G1B_fact)) if 10>G1B_fact[i]-G1B_opt[i]>=0]\n",
    "G4B_dif = [G4B_fact[i]-G4B_opt[i] for i in range(len(G4B_fact)) if 10>G4B_fact[i]-G4B_opt[i]>=0]\n",
    "\n",
    "G1B_dif = G1B_dif[0:min(len(G1B_dif),len(G4B_dif))]\n",
    "G4B_dif = G4B_dif[0:min(len(G1B_dif),len(G4B_dif))]\n",
    "\n",
    "G1B_dif = G1B_dif[0:3600]\n",
    "G4B_dif = G4B_dif[0:3600]\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': G1B_dif + G4B_dif ,\n",
    "    'model': ['1B'] * len(G1B_dif) + ['3B'] * len(G4B_dif) \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=palette, ax=ax, bins=np.arange(-0.5, 9, 1.0), legend=False, kde=False, multiple=\"dodge\")  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[0], edgecolor=\"white\", label=\"Gemma-3-1B-In\"),  # Color and label for 1B\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Gemma-3-4B-In\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "ax.axvline(np.mean(G1B_dif), color=palette[0], linestyle=\"--\")\n",
    "ax.axvline(np.mean(G4B_dif), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_xlim([-0.5,6])\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in provider profit  (units of $c_0$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "ax.set_xticks([ 0,1,2,3,4,5], [r\"0\",r\"1\",r\"2\",r\"3\",r\"4\",r\"5\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_G_absolute.pdf', dpi=300)\n",
    "print(len(G1B_dif))\n",
    "print(len(G4B_dif))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f896582",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/optimal_tokens_M8B.pkl', 'rb') as file:\n",
    "    M8B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/tokens_M8B.pkl', 'rb') as file:\n",
    "    M8B_fact = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "M8B_dif = [M8B_fact[i]-M8B_opt[i] for i in range(len(M8B_fact)) if 10>M8B_fact[i]-M8B_opt[i]>=0]\n",
    "M8B_dif=M8B_dif[0:3600]\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)\n",
    "width_pt = 469\n",
    "palette = sns.color_palette('husl', 2)\n",
    "\n",
    "utils.latexify() # Computer Modern, with TeX\n",
    "# utils.latexify(font_serif='Times New Roman', font_size=10, usetex=False) # Times New Roman, without TeX\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ratios': M8B_dif ,\n",
    "    'model': ['1B'] * len(M8B_dif) \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "fig_width, fig_height = utils.get_fig_dim(width_pt, fraction=0.6)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "\n",
    "sns.histplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1],palette[0]], ax=ax, bins=np.arange(-0.5, 9, 1.0), legend=False, kde=False, multiple=\"dodge\")  # Histogram with KDE\n",
    "\n",
    "#sns.rugplot(data = df, x=\"ratios\",hue=\"model\", palette=[palette[1], palette[2], palette[0]], alpha=0.5, legend=True)  # Rug plot for individual observations\n",
    "\n",
    "\n",
    "# Define custom legend elements\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Ministral-8B-Instruct-2410\"),  # Color and label for 1B\n",
    "    #Patch(facecolor=palette[1], edgecolor=\"white\", label=\"Gemma-3-4B-In\"),  # Color and label for 3B\n",
    "    #Patch(facecolor=palette[0], edgecolor=\"white\", label=\"3.1-8B-Instruct\")  # Color and label for 8B\n",
    "]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=\"7.5\", frameon=True)\n",
    "\n",
    "ax.axvline(np.mean(M8B_dif), color=palette[1], linestyle=\"--\")\n",
    "\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_xlim([-0.5,8])\n",
    "sns.despine(ax=ax)\n",
    "ax.set_xlabel(r\"Change in provider profit  (units of $c_0$)\")\n",
    "ax.set_ylabel(\"Number of outputs\", fontsize=8)\n",
    "ax.set_xticks([ 0,1,2,3,4,5], [r\"0\",r\"1\",r\"2\",r\"3\",r\"4\",r\"5\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('/NL/token-pricing/work/figures/dp/hist_dp_M_absolute.pdf', dpi=300)\n",
    "print(len(M8B_dif))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed7ba6",
   "metadata": {},
   "source": [
    "# Plots c/p absolute diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9626e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/optimal_tokens_G1B.pkl', 'rb') as file:\n",
    "    G1B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/tokens_G1B.pkl', 'rb') as file:\n",
    "    G1B_fact = pickle.load(file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-1B/characters_G1B.pkl', 'rb') as file:\n",
    "    G1B_char = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/optimal_tokens_G4B.pkl', 'rb') as file:\n",
    "    G4B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/tokens_G4B.pkl', 'rb') as file:\n",
    "    G4B_fact = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/gemma-3-4B/characters_G4B.pkl', 'rb') as file:\n",
    "    G4B_char = pickle.load(file)\n",
    "    \n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/optimal_tokens_M8B.pkl', 'rb') as file:\n",
    "    M8B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/tokens_M8B.pkl', 'rb') as file:\n",
    "    M8B_fact = pickle.load(file)\n",
    "    \n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/mistral-8B/characters_M8B.pkl', 'rb') as file:\n",
    "    M8B_char = pickle.load(file)\n",
    "\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/optimal_tokens_L1B.pkl', 'rb') as file:\n",
    "    L1B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/tokens_L1B.pkl', 'rb') as file:\n",
    "    L1B_fact = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-1B-Instruct/characters_L1B.pkl', 'rb') as file:\n",
    "    L1B_char = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/optimal_tokens_L3B.pkl', 'rb') as file:\n",
    "    L3B_opt = pickle.load(file)\n",
    "    \n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/tokens_L3B.pkl', 'rb') as file:\n",
    "    L3B_fact = pickle.load(file)\n",
    "\n",
    "with open('/NL/token-pricing/work/outputs/dp_profit_increase/llama3.2-3B-Instruct/characters_L3B.pkl', 'rb') as file:\n",
    "    L3B_char = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "G1B_dif = [G1B_fact[i]-G1B_opt[i] for i in range(len(G1B_fact)) if 10>G1B_fact[i]-G1B_opt[i]>=0]\n",
    "G4B_dif = [G4B_fact[i]-G4B_opt[i] for i in range(len(G4B_fact)) if 10>G4B_fact[i]-G4B_opt[i]>=0]\n",
    "L1B_dif = [L1B_fact[i]-L1B_opt[i] for i in range(len(L1B_fact)) if 10>L1B_fact[i]-L1B_opt[i]>=0]\n",
    "L3B_dif = [L3B_fact[i]-L3B_opt[i] for i in range(len(L3B_fact)) if 10>L3B_fact[i]-L3B_opt[i]>=0]\n",
    "M8B_dif = [M8B_fact[i]-M8B_opt[i] for i in range(len(M8B_fact)) if 10>M8B_fact[i]-M8B_opt[i]>=0]\n",
    "\n",
    "min_len = min(len(L1B_dif),len(L3B_dif),len(G1B_dif),len(G4B_dif),len(M8B_dif))\n",
    "#print(min_len)\n",
    "L1B_dif = np.sum(L1B_dif[0:min_len])\n",
    "L3B_dif = np.sum(L3B_dif[0:min_len])\n",
    "G1B_dif = np.sum(G1B_dif[0:min_len])\n",
    "G4B_dif = np.sum(G4B_dif[0:min_len])\n",
    "M8B_dif = np.sum(M8B_dif[0:min_len])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d440a4",
   "metadata": {},
   "source": [
    "# Average and error estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1B_fact_ = [G1B_fact[i] for i in range(len(G1B_fact)) if 10>G1B_fact[i]-G1B_opt[i]>=0]\n",
    "G1B_opt_ = [G1B_opt[i] for i in range(len(G1B_fact)) if 10>G1B_fact[i]-G1B_opt[i]>=0]\n",
    "\n",
    "G4B_fact_ = [G4B_fact[i] for i in range(len(G4B_fact)) if 10>G4B_fact[i]-G4B_opt[i]>=0]\n",
    "G4B_opt_ = [G4B_opt[i] for i in range(len(G4B_fact)) if 10>G4B_fact[i]-G4B_opt[i]>=0]\n",
    "\n",
    "L1B_fact_ = [L1B_fact[i] for i in range(len(L1B_fact)) if 10>L1B_fact[i]-L1B_opt[i]>=0] \n",
    "L1B_opt_ = [L1B_opt[i] for i in range(len(L1B_fact)) if 10>L1B_fact[i]-L1B_opt[i]>=0]\n",
    "\n",
    "L3B_fact_ = [L3B_fact[i] for i in range(len(L3B_fact)) if 10>L3B_fact[i]-L3B_opt[i]>=0]\n",
    "L3B_opt_ = [L3B_opt[i] for i in range(len(L3B_fact)) if 10>L3B_fact[i]-L3B_opt[i]>=0]\n",
    "\n",
    "M8B_fact_ = [M8B_fact[i] for i in range(len(M8B_fact)) if 10>M8B_fact[i]-M8B_opt[i]>=0]\n",
    "M8B_opt_ = [M8B_opt[i] for i in range(len(M8B_fact)) if 10>M8B_fact[i]-M8B_opt[i]>=0]\n",
    "\n",
    "min_len_ = min(len(L1B_fact_), len(L1B_opt_), len(L3B_fact_), len(L3B_opt_), len(G1B_fact_), len(G1B_opt_), len(G4B_fact_), len(G4B_opt_), len(M8B_fact_), len(M8B_opt_))\n",
    "\n",
    "min_len_=3600\n",
    "\n",
    "G1B_fact_ = np.array(G1B_fact_[0:min_len_])\n",
    "G1B_opt_ = np.array(G1B_opt_[0:min_len_])\n",
    "G4B_fact_ = np.array(G4B_fact_[0:min_len_])\n",
    "G4B_opt_ = np.array(G4B_opt_[0:min_len_])\n",
    "L1B_fact_ = np.array(L1B_fact_[0:min_len_])\n",
    "L1B_opt_ = np.array(L1B_opt_[0:min_len_])\n",
    "L3B_fact_ = np.array(L3B_fact_[0:min_len_])\n",
    "L3B_opt_ = np.array(L3B_opt_[0:min_len_])\n",
    "M8B_fact_ = np.array(M8B_fact_[0:min_len_])\n",
    "M8B_opt_ = np.array(M8B_opt_[0:min_len_])\n",
    "\n",
    "G1B_char_ = np.array(G1B_char[0:min_len_])\n",
    "G4B_char_ = np.array(G4B_char[0:min_len_])\n",
    "L1B_char_ = np.array(L1B_char[0:min_len_])\n",
    "L3B_char_ = np.array(L3B_char[0:min_len_])\n",
    "M8B_char_ = np.array(M8B_char[0:min_len_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1B_fact_batch = []\n",
    "G4B_fact_batch = []\n",
    "L1B_fact_batch = []\n",
    "L3B_fact_batch = []\n",
    "M8B_fact_batch = []\n",
    "\n",
    "G1B_opt_batch = []\n",
    "G4B_opt_batch = []\n",
    "L1B_opt_batch = []\n",
    "L3B_opt_batch = []\n",
    "M8B_opt_batch = []\n",
    "\n",
    "G1B_dif_batch = []\n",
    "G4B_dif_batch = []\n",
    "L1B_dif_batch = []\n",
    "L3B_dif_batch = []\n",
    "M8B_dif_batch = []\n",
    "\n",
    "L1B_char_batch = []\n",
    "L3B_char_batch = []\n",
    "G1B_char_batch = []\n",
    "G4B_char_batch = []\n",
    "M8B_char_batch = []\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    G1B_fact_batch.append(np.sum(G1B_fact_[i*600:(i+1)*600]))\n",
    "    G4B_fact_batch.append(np.sum(G4B_fact_[i*600:(i+1)*600]))\n",
    "    L1B_fact_batch.append(np.sum(L1B_fact_[i*600:(i+1)*600]))\n",
    "    L3B_fact_batch.append(np.sum(L3B_fact_[i*600:(i+1)*600]))\n",
    "    M8B_fact_batch.append(np.sum(M8B_fact_[i*600:(i+1)*600]))\n",
    "    \n",
    "    G1B_opt_batch.append(np.sum(G1B_opt_[i*600:(i+1)*600]))\n",
    "    G4B_opt_batch.append(np.sum(G4B_opt_[i*600:(i+1)*600]))\n",
    "    L1B_opt_batch.append(np.sum(L1B_opt_[i*600:(i+1)*600]))\n",
    "    L3B_opt_batch.append(np.sum(L3B_opt_[i*600:(i+1)*600]))\n",
    "    M8B_opt_batch.append(np.sum(M8B_opt_[i*600:(i+1)*600]))\n",
    "    \n",
    "    G1B_dif_batch.append(np.sum(G1B_fact_[i*600:(i+1)*600]-G1B_opt_[i*600:(i+1)*600]))\n",
    "    G4B_dif_batch.append(np.sum(G4B_fact_[i*600:(i+1)*600]-G4B_opt_[i*600:(i+1)*600]))\n",
    "    L1B_dif_batch.append(np.sum(L1B_fact_[i*600:(i+1)*600]-L1B_opt_[i*600:(i+1)*600]))\n",
    "    L3B_dif_batch.append(np.sum(L3B_fact_[i*600:(i+1)*600]-L3B_opt_[i*600:(i+1)*600]))\n",
    "    M8B_dif_batch.append(np.sum(M8B_fact_[i*600:(i+1)*600]-M8B_opt_[i*600:(i+1)*600]))\n",
    "    \n",
    "    L1B_char_batch.append(np.sum(L1B_char_[i*600:(i+1)*600]))\n",
    "    L3B_char_batch.append(np.sum(L3B_char_[i*600:(i+1)*600]))\n",
    "    G1B_char_batch.append(np.sum(G1B_char_[i*600:(i+1)*600]))\n",
    "    G4B_char_batch.append(np.sum(G4B_char_[i*600:(i+1)*600]))\n",
    "    M8B_char_batch.append(np.sum(M8B_char_[i*600:(i+1)*600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7371dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(L3B_fact_batch))\n",
    "# print(np.std(L3B_fact_batch))\n",
    "\n",
    "# print(np.mean(L3B_opt_batch))\n",
    "# print(np.std(L3B_opt_batch))\n",
    "\n",
    "# print(np.mean(L3B_dif_batch))\n",
    "# print(np.std(L3B_dif_batch))\n",
    "\n",
    "\n",
    "\n",
    "print(   np.mean((np.array(L1B_char_batch) - np.array(L1B_fact_batch) )/ (np.array(L1B_fact_batch)) * 100) )\n",
    "print(   np.std((np.array(L1B_char_batch) - np.array(L1B_fact_batch) )/ (np.array(L1B_fact_batch)) * 100)  )\n",
    "\n",
    "print(   np.mean((np.array(L3B_char_batch) - np.array(L3B_fact_batch) )/ (np.array(L3B_fact_batch)) * 100) )\n",
    "print(   np.std((np.array(L3B_char_batch) - np.array(L3B_fact_batch) )/ (np.array(L3B_fact_batch)) * 100)  )\n",
    "\n",
    "print(   np.mean((np.array(G1B_char_batch) - np.array(G1B_fact_batch) )/ (np.array(G1B_fact_batch)) * 100) )\n",
    "print(   np.std((np.array(G1B_char_batch) - np.array(G1B_fact_batch) )/ (np.array(G1B_fact_batch)) * 100)  )\n",
    "\n",
    "print(   np.mean((np.array(G4B_char_batch) - np.array(G4B_fact_batch) )/ (np.array(G4B_fact_batch)) * 100) )\n",
    "print(   np.std((np.array(G4B_char_batch) - np.array(G4B_fact_batch) )/ (np.array(G4B_fact_batch)) * 100)  )\n",
    "\n",
    "print(   np.mean((np.array(M8B_char_batch) - np.array(M8B_fact_batch) )/ (np.array(M8B_fact_batch)) * 100) )\n",
    "print(   np.std((np.array(M8B_char_batch) - np.array(M8B_fact_batch) )/ (np.array(M8B_fact_batch)) * 100)  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7608d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[3]['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "with open('/NL/token-pricing/work/src/shortest_vs_factual_modelLlama-3.2-1B-Instruct_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "char_3 = 0\n",
    "tok_3 = 0\n",
    "\n",
    "char_4 = 0\n",
    "tok_4 = 0\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for i in range(0,100):\n",
    "     char_1 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_1 += len(data[i]['output'][0])\n",
    "\n",
    "for i in range(100,200):\n",
    "     char_2 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_2 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(200,300):\n",
    "     char_3 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_3 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(300,400):\n",
    "     char_4 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_4 += len(data[i]['output'][0])\n",
    "\n",
    "print(np.mean(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))\n",
    "print(np.std(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "with open('/NL/token-pricing/work/src/shortest_vs_factual_modelLlama-3.2-3B-Instruct_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "char_3 = 0\n",
    "tok_3 = 0\n",
    "\n",
    "char_4 = 0\n",
    "tok_4 = 0\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for i in range(0,100):\n",
    "     char_1 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_1 += len(data[i]['output'][0])\n",
    "\n",
    "for i in range(100,200):\n",
    "     char_2 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_2 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(200,300):\n",
    "     char_3 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_3 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(300,400):\n",
    "     char_4 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_4 += len(data[i]['output'][0])\n",
    "\n",
    "print(np.mean(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))\n",
    "print(np.std(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512db645",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "with open('/NL/token-pricing/work/src/shortest_vs_factual_modelGemma-3-1b-it_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "char_3 = 0\n",
    "tok_3 = 0\n",
    "\n",
    "char_4 = 0\n",
    "tok_4 = 0\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for i in range(0,100):\n",
    "     char_1 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_1 += len(data[i]['output'][0])\n",
    "\n",
    "for i in range(100,200):\n",
    "     char_2 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_2 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(200,300):\n",
    "     char_3 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_3 += len(data[i]['output'][0])\n",
    "     \n",
    "for i in range(300,400):\n",
    "     char_4 += len(tokenizer.decode(data[i]['output'][0]))\n",
    "     tok_4 += len(data[i]['output'][0])\n",
    "\n",
    "print(np.mean(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))\n",
    "print(np.std(np.array( (char_1/tok_1,char_2/tok_2,char_3/tok_3,char_4/tok_4)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db15a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral\n",
      "Mean CPT 4.378779665184674\n",
      "Mean overchard 337.8779665184675\n",
      "Mean std 4.93390625833191\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"mistralai/Ministral-8B-Instruct-2410\")\n",
    "with open('/NL/token-pricing/work/outputs/fixed_string/shortest_vs_factual_modelMinistral-8B-Instruct-2410_p1.0_kNone_numseq3_numprompts600_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "char_3 = 0\n",
    "tok_3 = 0\n",
    "\n",
    "\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for prompt_id in range(100):\n",
    "     char_1 += len(tokenizer.decode(  data[prompt_id][\"output\"][0]  ))\n",
    "     tok_1 += len( data[prompt_id][\"output\"][0]  )\n",
    "\n",
    "     char_2 += len(tokenizer.decode(  data[prompt_id][\"output\"][1]  ))\n",
    "     tok_2 += len( data[prompt_id][\"output\"][1]  )\n",
    "\n",
    "\n",
    "     char_3 += len(tokenizer.decode(  data[prompt_id][\"output\"][2]  ))\n",
    "     tok_3 += len( data[prompt_id][\"output\"][2]  )\n",
    "\n",
    "print(\"Mistral\")\n",
    "print( \"Mean CPT\", np.mean(  np.array(  [char_1/tok_1, char_2/tok_2, char_3/tok_3] )) ) \n",
    "\n",
    "print(\"Mean overchard\", np.mean(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 , char_3/tok_3 - 1] )))\n",
    "\n",
    "print(\"Mean std\", np.std(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 , char_3/tok_3 - 1] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55998618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n",
      "Mean CPT 4.4493117865535226\n",
      "Mean overchard 344.93117865535226\n",
      "Mean std 0.11850470973035954\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "with open('/NL/token-pricing/work/outputs/fixed_string/shortest_vs_factual_modelLlama-3.2-1B-Instruct_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "\n",
    "\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for prompt_id in range(100):\n",
    "     char_1 += len(tokenizer.decode(  data[prompt_id][\"output\"][0]  ))\n",
    "     tok_1 += len( data[prompt_id][\"output\"][0]  )\n",
    "\n",
    "     char_2 += len(tokenizer.decode(  data[prompt_id][\"output\"][1]  ))\n",
    "     tok_2 += len( data[prompt_id][\"output\"][1]  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"L1\")\n",
    "print( \"Mean CPT\", np.mean(  np.array(  [char_1/tok_1, char_2/tok_2] )) ) \n",
    "\n",
    "print(\"Mean overchard\", np.mean(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))\n",
    "\n",
    "print(\"Mean std\", np.std(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4a1c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L3\n",
      "Mean CPT 4.450820858936394\n",
      "Mean overchard 345.0820858936395\n",
      "Mean std 6.061609121023309\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "with open('/NL/token-pricing/work/outputs/fixed_string/shortest_vs_factual_modelLlama-3.2-3B-Instruct_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for prompt_id in range(100):\n",
    "     char_1 += len(tokenizer.decode(  data[prompt_id][\"output\"][0]  ))\n",
    "     tok_1 += len( data[prompt_id][\"output\"][0]  )\n",
    "\n",
    "     char_2 += len(tokenizer.decode(  data[prompt_id][\"output\"][1]  ))\n",
    "     tok_2 += len( data[prompt_id][\"output\"][1]  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"L3\")\n",
    "print( \"Mean CPT\", np.mean(  np.array(  [char_1/tok_1, char_2/tok_2] )) ) \n",
    "\n",
    "print(\"Mean overchard\", np.mean(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))\n",
    "\n",
    "print(\"Mean std\", np.std(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65f6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1\n",
      "Mean CPT 4.088040241583179\n",
      "Mean overchard 308.8040241583179\n",
      "Mean std 1.4064245341774608\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "with open('/NL/token-pricing/work/outputs/fixed_string/shortest_vs_factual_modelGemma-3-1b-it_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "\n",
    "\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for prompt_id in range(100):\n",
    "     char_1 += len(tokenizer.decode(  data[prompt_id][\"output\"][0]  ))\n",
    "     tok_1 += len( data[prompt_id][\"output\"][0]  )\n",
    "\n",
    "     char_2 += len(tokenizer.decode(  data[prompt_id][\"output\"][1]  ))\n",
    "     tok_2 += len( data[prompt_id][\"output\"][1]  )\n",
    "\n",
    "\n",
    "\n",
    "print(\"G1\")\n",
    "print( \"Mean CPT\", np.mean(  np.array(  [char_1/tok_1, char_2/tok_2] )) ) \n",
    "\n",
    "print(\"Mean overchard\", np.mean(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))\n",
    "\n",
    "print(\"Mean std\", np.std(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5af88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G4\n",
      "Mean CPT 4.208428841519693\n",
      "Mean overchard 320.8428841519692\n",
      "Mean std 5.655655800247359\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"google/gemma-3-4b-It\")\n",
    "with open('/NL/token-pricing/work/outputs/fixed_string/shortest_vs_factual_modelGemma-3-4b-it_p1.0_kNone_numseq2_numprompts400_maxoutlen200_temp1.0_idare you .pkl', 'rb') as file:\n",
    "     data = pickle.load(file)\n",
    "\n",
    "char_1 = 0\n",
    "tok_1 = 0\n",
    "\n",
    "char_2 = 0\n",
    "tok_2 = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#iterate over the first 100 plots and add number of characters and of tokens\n",
    "for prompt_id in range(100):\n",
    "     char_1 += len(tokenizer.decode(  data[prompt_id][\"output\"][0]  ))\n",
    "     tok_1 += len( data[prompt_id][\"output\"][0]  )\n",
    "\n",
    "     char_2 += len(tokenizer.decode(  data[prompt_id][\"output\"][1]  ))\n",
    "     tok_2 += len( data[prompt_id][\"output\"][1]  )\n",
    "\n",
    "\n",
    "print(\"G4\")\n",
    "print( \"Mean CPT\", np.mean(  np.array(  [char_1/tok_1, char_2/tok_2] )) ) \n",
    "\n",
    "print(\"Mean overchard\", np.mean(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))\n",
    "\n",
    "print(\"Mean std\", np.std(  100 * np.array(  [char_1/tok_1 -1 , char_2/tok_2 -1 ] )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
